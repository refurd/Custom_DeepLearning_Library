{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenzorok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az adatokat tenzorok reprezentálják. A tenzorok kezelése hasonló a numpy-hoz bár, a függvények nevei eltérnek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tenzor létrehozása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor((5, 6), dtype=torch.float32)  # itt is sor, oszlop\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.eye(4)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.zeros((3, 2))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.ones((3, 7), dtype=bool)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9434, -2.2135,  0.2787],\n",
      "        [ 1.4550, -1.1730, -1.1258],\n",
      "        [ 1.0159,  0.7988, -2.1531]])\n"
     ]
    }
   ],
   "source": [
    "e = torch.normal(mean=torch.zeros(3, 3), std=torch.ones(3, 3))\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 8], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# ha rendelkezésre áll másik hardware is, akkor a tensort át lehet tenni gpu-ra illetve vissza\n",
    "f = torch.as_tensor([5, 6, 8], dtype=torch.int32, device=torch.device('cuda'))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 8]\n"
     ]
    }
   ],
   "source": [
    "# visszafelé\n",
    "g = f.cpu().detach().numpy()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### műveletek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2077, -0.0185,  0.2137],\n",
      "        [ 0.1829, -1.5721,  1.7716],\n",
      "        [-0.7753,  1.1038,  1.3150]])\n"
     ]
    }
   ],
   "source": [
    "# összeadás\n",
    "a = torch.normal(mean=torch.zeros(3, 3), std=torch.ones(3, 3))\n",
    "b = torch.normal(mean=torch.zeros(3, 3), std=torch.ones(3, 3))\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5054, 2.9784, 4.0083])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redukció\n",
    "a.sum(dim=0)  # axis helyett dim van"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9365)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = a.unsqueeze(0)  # hozzáad egy plusz dimenziót, dim=0-nál\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = a.unsqueeze(1)\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3171,  1.3075,  1.6865],\n",
      "        [ 0.3816, -0.2656,  1.5144],\n",
      "        [ 0.4409,  1.9365,  0.8073]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    nan,  0.2681,  0.5227],\n",
       "        [-0.9634,     nan,  0.4151],\n",
       "        [-0.8190,  0.6609, -0.2140]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vektorizáció\n",
    "print(a)\n",
    "torch.log(a)  # nan ott lehet, ahol negatív a bemenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Példa az MNIST-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2051 60000 28 28\n",
      "Reading images: [100%]\n",
      "2049 60000\n",
      "Reading labels: [100%]\n",
      "2051 10000 28 28\n",
      "Reading images: [100%]\n",
      "2049 10000\n",
      "Reading labels: [100%]\n"
     ]
    }
   ],
   "source": [
    "from pckutils import mnist\n",
    "mnist_data = mnist.load_mnist('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the images\n",
    "reshape = lambda img: img.reshape((mnist_data.rows, mnist_data.cols))\n",
    "mnist_data.X_train = [reshape(img) for img in mnist_data.X_train]\n",
    "mnist_data.X_test = [reshape(img) for img in mnist_data.X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adat kezelés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az alábbiakra fogunk figyelni az adatbetöltés során:\n",
    "\n",
    "* legyen tanításhoz és validációhoz is adat\n",
    "* augmentációt is fogunk használni a batchek mintavételezése közben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining paramters\n",
    "batch_size = 32\n",
    "split_ratio = 0.8\n",
    "device = torch.device(\"cuda\")  # \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ez a Dataset, amit a Pytorch saját Loader-e vár\n",
    "class MnistDataset(Dataset):\n",
    "    def __init__(self, device, images, labels, transform=lambda x: np.expand_dims(x, axis=0)):  # a transformer olyan képet ad, aminek már van channelje\n",
    "        self.device = device\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_ = self.images[index]\n",
    "        image = self.transform(image_)  # itt alkalmazzuk az augmentciót\n",
    "        label = self.labels[index]\n",
    "        sample = {\n",
    "            'image_id': index,\n",
    "            'image': torch.tensor(image, dtype=torch.float, device=self.device),\n",
    "            'target': torch.tensor(label, dtype=torch.long, device=self.device)\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "# definiáljuk az adatbetöltőket\n",
    "\n",
    "# felbontjuk azadatot\n",
    "indices = list(range(mnist_data.num_train_imgs))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split_index = int(len(indices) * split_ratio)\n",
    "idices_for_train = indices[0:split_index]\n",
    "indices_for_validation = indices[split_index:]\n",
    "\n",
    "# Training loader\n",
    "training_img = [mnist_data.X_train[idx] for idx in idices_for_train]  # list of images\n",
    "training_label = [mnist_data.Y_train[idx] for idx in idices_for_train]\n",
    "\n",
    "augmenter = transforms.Compose(  # tipikus augmentáció tartalmazza: forgatás, nyújtás, vágás, traszláció, zaj, kontraszt, fényesség stb.\n",
    "    [   transforms.ToPILImage(),\n",
    "        transforms.RandomAffine([-90, 90]),  # forgatás\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "dataset = MnistDataset(device, training_img, training_label, augmenter)\n",
    "loader_train = DataLoader(dataset, batch_size)\n",
    "\n",
    "# Validation loader\n",
    "validation_img = [mnist_data.X_train[idx] for idx in indices_for_validation]  # képek listája\n",
    "validation_label = [mnist_data.Y_train[idx] for idx in indices_for_validation]\n",
    "\n",
    "dataset = MnistDataset(device, validation_img, validation_label)\n",
    "loader_validation = DataLoader(dataset, batch_size)\n",
    "\n",
    "# Test loader\n",
    "test_img = mnist_data.X_test  # képek listája\n",
    "test_label = mnist_data.Y_test\n",
    "\n",
    "dataset = MnistDataset(device, test_img, test_label)\n",
    "loader_test = DataLoader(dataset, 1)  # egyenként fogjuk tesztelni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell építés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTclassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTclassifier, self).__init__()\n",
    "        # creating the network architecture\n",
    "\n",
    "        # expected input size: (batch, 1, 28, 28)\n",
    "        self.conv1_1 = nn.Conv2d(1, 8, (3, 3), stride=1)     # (., 8, 26, 26)\n",
    "        self.conv1_2 = nn.Conv2d(8, 16, (3, 3), stride=1)    # (., 16, 24, 24)\n",
    "        self.conv1_3 = nn.Conv2d(16, 16, (2, 2), stride=2)    # (., 16, 12, 12)\n",
    "        self.conv1_4 = nn.Conv2d(16, 8, (3, 3), stride=1)   # (., 8, 10, 10)\n",
    "        \n",
    "        self.linear = nn.Linear(800, 10)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        temp = self.relu(self.conv1_1(x))\n",
    "        temp = self.relu(self.conv1_2(temp))\n",
    "        temp = self.relu(self.conv1_3(temp))\n",
    "        temp = self.relu(self.conv1_4(temp))\n",
    "        temp = temp.view(-1, 800)\n",
    "        temp = self.linear(temp)\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTclassifier(\n",
       "  (conv1_1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_3): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv1_4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (linear): Linear(in_features=800, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# példányosítsunk is egyet\n",
    "model = MNISTclassifier()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A tanítás folyamata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "\n",
    "epochs = 6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training at 2020-11-08 22:20:18.965081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\adambudai\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status at: (epoch: 0, i: 1499 ) with validation loss: 41.990800\n",
      " Current epoch 0 and global counter 1500Current status at: (epoch: 1, i: 1499 ) with validation loss: 40.692638\n",
      " Current epoch 1 and global counter 3000Current status at: (epoch: 2, i: 1499 ) with validation loss: 33.464447\n",
      " Current epoch 2 and global counter 4500Current status at: (epoch: 3, i: 1499 ) with validation loss: 34.656633\n",
      " Current epoch 3 and global counter 6000Current status at: (epoch: 4, i: 1499 ) with validation loss: 34.829066\n",
      " Current epoch 4 and global counter 7500Current status at: (epoch: 5, i: 1499 ) with validation loss: 26.592075\n",
      " Current epoch 5 and global counter 9000Training has finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Started training at {}\".format(datetime.now()))\n",
    "\n",
    "global_counter = 0\n",
    "\n",
    "def _validation(epoch, index, global_counter):\n",
    "    counter = 0\n",
    "    loss_sum = 0.0\n",
    "    for sample in loader_validation:\n",
    "        counter += 1\n",
    "        image = sample['image']\n",
    "        target = sample['target']\n",
    "        predicted = model(image)\n",
    "        loss = criterion(predicted, target)\n",
    "        loss_sum += loss.cpu().detach().numpy()  # a kiszámolt loss is a gpu-n van, vissza kell hozni\n",
    "        del loss\n",
    "\n",
    "    loss_mean = loss_sum / counter\n",
    "    print(\"Current status at: (epoch: %d, i: %d) with validation loss: %f\"%(epoch, index, loss_mean))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for index, sample in enumerate(loader_train):\n",
    "        global_counter += 1\n",
    "\n",
    "        image = sample['image']\n",
    "        target = sample['target']\n",
    "        \n",
    "        predicted = model(image)\n",
    "        loss = criterion(predicted, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss = loss.cpu().detach().numpy()\n",
    "\n",
    "    _validation(epoch, index, global_counter)\n",
    "    print(\"\\r Current epoch {} and global counter {}\".format(epoch, global_counter), end=\"\")\n",
    "print(\"Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eredmény tesztelése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "9 9\n",
      "8 8\n",
      "5 5\n",
      "4 4\n",
      "0 0\n",
      "8 8\n",
      "9 9\n",
      "6 6\n",
      "0 0\n",
      "1 1\n",
      "7 7\n",
      "2 2\n",
      "4 4\n",
      "9 9\n",
      "8 8\n",
      "6 6\n",
      "0 0\n",
      "1 1\n",
      "6 6\n",
      "Correctly labeled 9429 out of 10000\n"
     ]
    }
   ],
   "source": [
    "# megszámoljuk hány esetben ad jó eredményt a megoldás\n",
    "counter = 0\n",
    "correctly_labeled = 0\n",
    "for sample in loader_test:\n",
    "    counter += 1\n",
    "    image = sample['image']\n",
    "    target = sample['target']\n",
    "    predicted = torch.argmax(model(image))\n",
    "\n",
    "    if predicted == target:\n",
    "        if (counter%500 == 0):\n",
    "            print(predicted.cpu().detach().numpy(), target[0].cpu().detach().numpy())\n",
    "        correctly_labeled += 1\n",
    "\n",
    "print(\"Correctly labeled {} out of {}\".format(correctly_labeled, counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell mentése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'minst_weights.pt'\n",
    "checkpoint = {\n",
    "    'mnist_state': model.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTclassifier(\n",
       "  (conv1_1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_3): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv1_4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (linear): Linear(in_features=800, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visszatöltés\n",
    "model2 = MNISTclassifier()\n",
    "checkpoint = torch.load(path)\n",
    "model2.load_state_dict(checkpoint['mnist_state'])\n",
    "model2.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
